{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "from custom_tiny_bench.processor.benchmark_processor import (\n",
    "    BenchmarkConfig,\n",
    "    EvaluationResult,\n",
    ")\n",
    "from custom_tiny_bench.tiny_benchmark import TinyBenchmark\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    force = True)\n",
    "\n",
    "save_dir = Path(\"data\")\n",
    "bm_configs: list[BenchmarkConfig] = [\n",
    "    BenchmarkConfig(\n",
    "        name=\"gqa\",\n",
    "        results=[\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"data/gqa/instructblip-vicuna-7b/gqa-formatted-predictions.json\",\n",
    "                model=\"instructblip-vicuna-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"data/gqa/llava-v1.5-7b/gqa-formatted-predictions.json\",\n",
    "                model=\"llava-v1.5-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"data/gqa/prism-clip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-clip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"data/gqa/prism-dinosiglip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-dinosiglip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"data/gqa/prism-siglip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-siglip+7b\",\n",
    "            ),\n",
    "        ],\n",
    "        question_file=\"data/gqa/questions.json\",\n",
    "        subscenario_keyword=\"structural_type\"\n",
    "    )\n",
    "]\n",
    "train_size: int | float = 4\n",
    "device = \"cpu\"\n",
    "number_item: int = 100\n",
    "random_state: int = 42\n",
    "clustering: Literal[\"irt\", \"correct.\"] = \"irt\"\n",
    "p_irt: bool = True\n",
    "gp_irt = True\n",
    "epochs = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinybm = TinyBenchmark(save_dir)\n",
    "# print(tinybm.bm_to_proc[\"gqa\"].predictions.predictions_per_model)\n",
    "# tinybm.prepare_data(bm_configs)\n",
    "# tinybm.train_irt(train_size, device)\n",
    "# tinybm.get_anchors(number_item, random_state, clusterting)\n",
    "# tinybm.estimate_performance(p_irt, gp_irt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/questions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/instructblip-vicuna-7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Naive accuracy of instructblip-vicuna-7b: 0.48386\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/llava-v1.5-7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Naive accuracy of llava-v1.5-7b: 0.61735\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/prism-clip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Naive accuracy of prism-clip+7b: 0.64573\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/prism-dinosiglip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Naive accuracy of prism-dinosiglip+7b: 0.65169\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening data/gqa/prism-siglip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Naive accuracy of prism-siglip+7b: 0.64406\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:[create_correctness_array] Shape of correctness array (5, 12578)\n",
      "INFO:custom_tiny_bench.tiny_benchmark:[prepare_data] correctness_array.shape == (5, 12578)\n",
      "INFO:custom_tiny_bench.tiny_benchmark:compare has 589 number of questions\n",
      "INFO:custom_tiny_bench.tiny_benchmark:query has 6805 number of questions\n",
      "INFO:custom_tiny_bench.tiny_benchmark:verify has 2252 number of questions\n",
      "INFO:custom_tiny_bench.tiny_benchmark:choose has 1129 number of questions\n",
      "INFO:custom_tiny_bench.tiny_benchmark:logical has 1803 number of questions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: ['instructblip-vicuna-7b', 'llava-v1.5-7b', 'prism-clip+7b', 'prism-dinosiglip+7b', 'prism-siglip+7b']\n"
     ]
    }
   ],
   "source": [
    "tinybm.prepare_data(bm_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:38:21] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model                       cli.py:112\n",
      "[22:38:21] amortized: False                                       dataset.py:112\n",
      "[22:38:21] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 12578,           training.py:134\n",
      "           'num_subjects': 3}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           12578, 'num_subjects': 3, 'priors': 'hierarchical',                  \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([37734]) torch.Size([37734])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss        ┃ Best Loss   ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 235724.3136 │ 235724.3136 │ 0.1000 │\n",
      "│ 201   │ 35649.9530  │ 29160.0017  │ 0.0980 │\n",
      "│ 401   │ 30291.4588  │ 24540.6489  │ 0.0961 │\n",
      "│ 601   │ 24957.4398  │ 23665.9063  │ 0.0942 │\n",
      "│ 801   │ 23350.4902  │ 22812.4986  │ 0.0923 │\n",
      "│ 1001  │ 26271.1776  │ 22059.7453  │ 0.0905 │\n",
      "│ 1201  │ 23945.8695  │ 22059.7453  │ 0.0887 │\n",
      "│ 1401  │ 27096.2227  │ 21857.4224  │ 0.0869 │\n",
      "│ 1601  │ 24673.4995  │ 21434.0870  │ 0.0852 │\n",
      "│ 1801  │ 22819.6858  │ 21406.9156  │ 0.0835 │\n",
      "│ 2000  │ 23667.7291  │ 21406.9156  │ 0.0819 │\n",
      "└───────┴───��─────────┴─────────────┴────────┘[22:38:41] Train time: 20.1720769405365                               cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:22<00:22, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:38:43] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model                       cli.py:112\n",
      "[22:38:43] amortized: False                                       dataset.py:112\n",
      "[22:38:43] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 12578,           training.py:134\n",
      "           'num_subjects': 3}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           12578, 'num_subjects': 3, 'priors': 'hierarchical',                  \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([37734]) torch.Size([37734])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss        ┃ Best Loss   ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 310767.8039 │ 310767.8039 │ 0.1000 │\n",
      "│ 201   │ 62631.3163  │ 41983.2959  │ 0.0980 │\n",
      "│ 401   │ 31806.5868  │ 31390.0218  │ 0.0961 │\n",
      "│ 601   │ 32024.7755  │ 28498.6331  │ 0.0942 │\n",
      "│ 801   │ 30663.3653  │ 27848.4440  │ 0.0923 │\n",
      "│ 1001  │ 28882.3269  │ 27801.6593  │ 0.0905 │\n",
      "│ 1201  │ 40282.0632  │ 26579.9498  │ 0.0887 │\n",
      "│ 1401  │ 28295.9090  │ 26158.8574  │ 0.0869 │\n",
      "│ 1601  │ 29708.1463  │ 25516.1045  │ 0.0852 │\n",
      "│ 1801  │ 30434.7300  │ 25395.1963  │ 0.0835 │\n",
      "│ 2000  │ 29931.8077  │ 25172.4828  │ 0.0819 │\n",
      "└───────┴───��─────────┴─────────────┴────────┘[22:39:09] Train time: 25.94125008583069                              cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:50<00:00, 25.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:39:12] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_dataset.jsonlines                      cli.py:111\n",
      "           output directory: data/irt_model                           cli.py:112\n",
      "[22:39:12] amortized: False                                       dataset.py:112\n",
      "[22:39:12] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 12578,           training.py:134\n",
      "           'num_subjects': 4}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           12578, 'num_subjects': 4, 'priors': 'hierarchical',                  \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([50312]) torch.Size([50312])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss        ┃ Best Loss   ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 171632.8829 │ 171632.8829 │ 0.1000 │\n",
      "│ 201   │ 43532.2740  │ 36155.5024  │ 0.0980 │\n",
      "│ 401   │ 39214.5827  │ 29919.0665  │ 0.0961 │\n",
      "│ 601   │ 35465.6821  │ 29862.4034  │ 0.0942 │\n",
      "│ 801   │ 30172.8440  │ 29862.4034  │ 0.0923 │\n",
      "│ 1001  │ 30719.1651  │ 29030.5645  │ 0.0905 │\n",
      "│ 1201  │ 29619.1673  │ 29030.5645  │ 0.0887 │\n",
      "│ 1401  │ 29795.4251  │ 28753.8606  │ 0.0869 │\n",
      "│ 1601  │ 29287.6982  │ 28649.3633  │ 0.0852 │\n",
      "│ 1801  │ 31464.0498  │ 28528.8978  │ 0.0835 │\n",
      "│ 2000  │ 29660.7990  │ 28528.8978  │ 0.0819 │\n",
      "└───────┴───��─────────┴─────────────┴────────┘[22:39:33] Train time: 20.881091833114624                             cli.py:122\n",
      "data/lambds.pickle\n"
     ]
    }
   ],
   "source": [
    "tinybm.train_irt(train_size, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_tiny_bench.tiny_benchmark:[Anchor points] scenario: gqa, avg. error: 0.0128091441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points [ 2819   102  9204 10786 12171  7025 10717  2781 11565  5975  7119  2435\n",
      "  5291  9817  1577  8157  8145  8807 12090  8300  8393   874 10515 10863\n",
      "  3146 11888  6145  1776  8101  2166  8552  7601  2281  1091 11168 10169\n",
      "   271   952  7269 12443  4113  7564  3876  4929  3746  4325  9090   340\n",
      "  2084 11412  7576  8654  1328  7276  8014  9209  1116  4028  5361  4615\n",
      "  9716  9511  9910   696 10351 10468 10171  5971 11271  4997  8507  6629\n",
      "  3520 10723  7378  9107 12523  5509  9763 12484  1684 12503 11433  6790\n",
      " 10866   346  7490  8061  4440  1098  5278  3499  2677  5882  2304  5993\n",
      "  6795  2289  1534  7230]\n"
     ]
    }
   ],
   "source": [
    "anchor = tinybm.get_anchors(number_item, random_state, clustering= clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IRT] predicted score for 0_th model in gqa: 0.722675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[p-IRT] predicted score for 0_th model in gqa: 0.755298\n",
      "[gp-IRT] predicted score for 0_th model in gqa: 0.723707\n"
     ]
    }
   ],
   "source": [
    "res = tinybm.estimate_performance(p_irt=p_irt, gp_irt=gp_irt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on gqa\n",
      "Model 0\n",
      "    [Balanced true accruacy] 0.73548\n",
      "    [Random] scenario: gqa, avg. error: 0.06548\n",
      "    [IRT] scenario: gqa, avg. error: 0.01281\n",
      "    [p-IRT] scenario: gqa, avg. error: 0.01981\n",
      "    [gp-IRT] scenario: gqa, avg. error: 0.01178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Random sampling \n",
    "qids = np.array(range(12578))\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "for scenario in tinybm.scenarios_position.keys():\n",
    "    random_points = rng.choice(qids, size=number_item, replace=False)\n",
    "    equal_weights = np.array([1/number_item for _ in range(number_item)])\n",
    "\n",
    "    Y_random = tinybm.test_data[:,tinybm.scenarios_position[scenario]][:,random_points]\n",
    "    Y_hat = (Y_random*equal_weights).sum(axis=1)\n",
    "    Balanced_true = (tinybm.balance_weights*tinybm.test_data)[:,tinybm.scenarios_position[scenario]].mean(axis=1) \n",
    "\n",
    "    print(f\"Result on {scenario}\")\n",
    "    for i in range(Balanced_true.shape[0]):\n",
    "        print(f\"Model {i}\")\n",
    "        print(f\"    [Balanced true accruacy] {Balanced_true[i]:.5f}\")\n",
    "        print(f\"    [Random] scenario: {scenario}, avg. error: {np.abs(Y_hat[i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [IRT] scenario: {scenario}, avg. error: {np.abs(res[0][scenario][i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [p-IRT] scenario: {scenario}, avg. error: {np.abs(res[1][scenario][i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [gp-IRT] scenario: {scenario}, avg. error: {np.abs(res[2][scenario][i]-Balanced_true[i]):.5f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
