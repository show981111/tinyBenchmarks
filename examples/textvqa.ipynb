{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# In order to import custom tiny bench from example directory\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "from custom_tiny_bench.processor.benchmark_processor import (\n",
    "    BenchmarkConfig,\n",
    "    EvaluationResult,\n",
    ")\n",
    "from custom_tiny_bench.tiny_benchmark import TinyBenchmark\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    force = True)\n",
    "\n",
    "save_dir = Path(\"../data\")\n",
    "bm_configs: list[BenchmarkConfig] = [\n",
    "    BenchmarkConfig(\n",
    "        name=\"gqa\",\n",
    "        results=[\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/gqa/instructblip-vicuna-7b/gqa-formatted-predictions.json\",\n",
    "                model=\"instructblip-vicuna-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/gqa/llava-v1.5-7b/gqa-formatted-predictions.json\",\n",
    "                model=\"llava-v1.5-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/gqa/prism-clip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-clip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/gqa/prism-dinosiglip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-dinosiglip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/gqa/prism-siglip+7b/gqa-formatted-predictions.json\",\n",
    "                model=\"prism-siglip+7b\",\n",
    "            ),\n",
    "        ],\n",
    "        question_file=\"../data/gqa/questions.json\",\n",
    "        subscenario_keyword=\"structural_type\"\n",
    "    ),\n",
    "    BenchmarkConfig(\n",
    "        name=\"text-vqa\",\n",
    "        results=[\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/text-vqa/instructblip-vicuna-7b/results+rank-0.json\",\n",
    "                model=\"instructblip-vicuna-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/text-vqa/llava-v1.5-7b/results+rank-0.json\",\n",
    "                model=\"llava-v1.5-7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/text-vqa/prism-clip+7b/results+rank-0.json\",\n",
    "                model=\"prism-clip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/text-vqa/prism-dinosiglip+7b/results+rank-0.json\",\n",
    "                model=\"prism-dinosiglip+7b\",\n",
    "            ),\n",
    "            EvaluationResult(\n",
    "                prediction_file=\"../data/text-vqa/prism-siglip+7b/results+rank-0.json\",\n",
    "                model=\"prism-siglip+7b\",\n",
    "            ),\n",
    "        ],\n",
    "        question_file=\"../data/text-vqa/annotations-textvqa-full.json\",\n",
    "    )\n",
    "]\n",
    "train_size: int | float = 4\n",
    "device = \"cpu\"\n",
    "number_item: int = 100\n",
    "random_state: int = 42\n",
    "clustering: Literal[\"irt\", \"correct.\"] = \"irt\"\n",
    "p_irt: bool = True\n",
    "gp_irt = True\n",
    "epochs = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinybm = TinyBenchmark(save_dir, balance=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/questions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/instructblip-vicuna-7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/llava-v1.5-7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/prism-clip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/prism-dinosiglip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/gqa/prism-siglip+7b/gqa-formatted-predictions.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 12578\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:[create_correctness_array] Shape of correctness array (5, 12578)\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/annotations-textvqa-full.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/instructblip-vicuna-7b/results+rank-0.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: ['instructblip-vicuna-7b', 'llava-v1.5-7b', 'prism-clip+7b', 'prism-dinosiglip+7b', 'prism-siglip+7b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/llava-v1.5-7b/results+rank-0.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 5000\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/prism-clip+7b/results+rank-0.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 5000\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/prism-dinosiglip+7b/results+rank-0.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 5000\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Opening ../data/text-vqa/prism-siglip+7b/results+rank-0.json\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:Number of predictions: 5000\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:[create_correctness_array] Shape of correctness array (5, 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: ['instructblip-vicuna-7b', 'llava-v1.5-7b', 'prism-clip+7b', 'prism-dinosiglip+7b', 'prism-siglip+7b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 8886.43it/s]\n",
      "INFO:custom_tiny_bench.processor.benchmark_processor:After binarize, error is [0.00248 0.0033  0.00224 0.00312 0.00322]\n",
      "INFO:custom_tiny_bench.tiny_benchmark:[prepare_data] correctness_array.shape == (5, 17578)\n"
     ]
    }
   ],
   "source": [
    "tinybm.prepare_data(bm_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:54:48] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: ../data/datasets/irt_val_dataset.jsonlines      cli.py:111\n",
      "           output directory: ../data/models/irt_val_model             cli.py:112\n",
      "[20:54:48] amortized: False                                       dataset.py:112\n",
      "[20:54:48] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 17578,           training.py:134\n",
      "           'num_subjects': 3}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           17578, 'num_subjects': 3, 'priors': 'hierarchical',                  \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([52734]) torch.Size([52734])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss        ┃ Best Loss   ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 236042.9160 │ 236042.9160 │ 0.1000 │\n",
      "│ 201   │ 81000.2463  │ 43175.3066  │ 0.0980 │\n",
      "│ 401   │ 39957.4162  │ 35724.7684  │ 0.0961 │\n",
      "│ 601   │ 48153.5147  │ 33431.4285  │ 0.0942 │\n",
      "│ 801   │ 37744.4683  │ 32575.6297  │ 0.0923 │\n",
      "│ 1001  │ 38098.4055  │ 31805.9014  │ 0.0905 │\n",
      "│ 1201  │ 38816.5549  │ 31805.9014  │ 0.0887 │\n",
      "│ 1401  │ 38927.5805  │ 31192.9218  │ 0.0869 │\n",
      "│ 1601  │ 33038.9837  │ 31192.9218  │ 0.0852 │\n",
      "│ 1801  │ 32912.3529  │ 30972.9015  │ 0.0835 │\n",
      "│ 2000  │ 31108.4268  │ 30841.8469  │ 0.0819 │\n",
      "└───────┴───��─────────┴─────────────┴────────┘[20:55:12] Train time: 24.272366046905518                             cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:26<00:26, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:17] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: ../data/datasets/irt_val_dataset.jsonlines      cli.py:111\n",
      "           output directory: ../data/models/irt_val_model             cli.py:112\n",
      "[20:55:17] amortized: False                                       dataset.py:112\n",
      "[20:55:17] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 17578,           training.py:134\n",
      "           'num_subjects': 3}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           17578, 'num_subjects': 3, 'priors': 'hierarchical',                  \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([52734]) torch.Size([52734])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss        ┃ Best Loss   ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 533165.8225 │ 533165.8225 │ 0.1000 │\n",
      "│ 201   │ 76578.7707  │ 58992.8934  │ 0.0980 │\n",
      "│ 401   │ 48071.9169  │ 47501.5471  │ 0.0961 │\n",
      "│ 601   │ 52502.2239  │ 40045.1080  │ 0.0942 │\n",
      "│ 801   │ 48526.6181  │ 37014.6962  │ 0.0923 │\n",
      "│ 1001  │ 42312.0495  │ 37014.6962  │ 0.0905 │\n",
      "│ 1201  │ 49260.9719  │ 37014.6962  │ 0.0887 │\n",
      "│ 1401  │ 38381.3071  │ 37014.6962  │ 0.0869 │\n",
      "│ 1601  │ 41015.1649  │ 36487.2817  │ 0.0852 │\n",
      "│ 1801  │ 38639.8204  │ 35673.3593  │ 0.0835 │\n",
      "│ 2000  │ 39087.4479  │ 35673.3593  │ 0.0819 │\n",
      "└───────┴───��─────────┴─────────────┴────────┘[20:55:49] Train time: 32.424376010894775                             cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:03<00:00, 31.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:52] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: ../data/datasets/irt_dataset.jsonlines          cli.py:111\n",
      "           output directory: ../data/models/irt_model                 cli.py:112\n",
      "[20:55:52] amortized: False                                       dataset.py:112\n",
      "[20:55:52] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 17578,           training.py:134\n",
      "           'num_subjects': 4}                                                   \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           17578, 'num_subjects': 4, 'priors': 'hierarchical',                  \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([70312]) torch.Size([70312])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss         ┃ Best Loss    ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 2266308.9358 │ 2266308.9358 │ 0.1000 │\n",
      "│ 201   │ 77581.7649   │ 76382.1920   │ 0.0980 │\n",
      "│ 401   │ 66893.2625   │ 59647.3390   │ 0.0961 │\n",
      "│ 601   │ 57659.2730   │ 51462.0967   │ 0.0942 │\n",
      "│ 801   │ 57573.2396   │ 50142.9185   │ 0.0923 │\n",
      "│ 1001  │ 49552.0500   │ 48951.5276   │ 0.0905 │\n",
      "│ 1201  │ 53920.0896   │ 48567.8295   │ 0.0887 │\n",
      "│ 1401  │ 51236.7430   │ 47174.5011   │ 0.0869 │\n",
      "│ 1601  │ 48369.0395   │ 47011.4715   │ 0.0852 │\n",
      "│ 1801  │ 50658.7705   │ 46387.6353   │ 0.0835 │\n",
      "│ 2000  │ 49636.6671   │ 46387.6353   │ 0.0819 │\n",
      "��───────┴──────────────┴──────────────┴────────┘[20:56:26] Train time: 34.506436824798584                             cli.py:122\n"
     ]
    }
   ],
   "source": [
    "tinybm.train_irt(train_size, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:custom_tiny_bench.tiny_benchmark:Points for gqa: [11525   479  7320  1545 12222  1308 11746 12289  1264  7145  9775  1191\n",
      " 10475  2080 10570  3702  1987  7522   312 10377    41  7739   708  4051\n",
      "  2901  1436  7115  1946 11551  3867  2240  2728  4701  9602 11073  3277\n",
      "  6162 10504  3202  1545  9525 11629  8216  5025    95 11664  1184  1658\n",
      "  7323   309  6283 11845  9590 12439  3766  2339  4641 12053 10447  5008\n",
      "  6852 10328 10482  8283  1691 10258  6505  4994  1179  9825 10468  2460\n",
      "  5192  4246  1011 11419  3266  7478 11773  4838  1378   342   547  2892\n",
      "  5816  5598  6821 11141 10613  3005  3376  8894  8395  3345 11208  5544\n",
      "  9588  9716  6775  3681]\n",
      "INFO:custom_tiny_bench.tiny_benchmark:Points for text-vqa: [ 860 3713 4524   67 3751 4075  459 3759 3797  600 4631 3456  845 4006\n",
      " 1768 4789 2974 2320 4644 4729  576  675 3716 2221 3565 3184 4475 4027\n",
      " 1434  694 2597  309 2188 2987 4040 1919 4561 2258 1099  393 1269 1660\n",
      " 3999 3624 1966 1487 3060 3302 3170 4376  100 2201 4400 4585 1193  812\n",
      " 3522 2508 3257 2949  398 4540 4346 3416 4124  230 2901 3385  824 2916\n",
      " 1050 3689  433 3044  302 1787 3088  902 1178 3461 4606 1919 2623 1799\n",
      " 4418 3578  826 2520 4077 4575 2068 1092 1916 3558  940  804   69 2824\n",
      " 2653 1997]\n",
      "INFO:custom_tiny_bench.tiny_benchmark:[Anchor points] scenario: gqa, avg. error: 0.0015900779\n",
      "INFO:custom_tiny_bench.tiny_benchmark:[Anchor points] scenario: text-vqa, avg. error: 0.0052000000\n"
     ]
    }
   ],
   "source": [
    "anchor = tinybm.get_anchors(number_item, random_state, clustering= clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.30it/s]\n",
      "INFO:custom_tiny_bench.estimator:[Naive accuracy]: 0.610000\n",
      "INFO:custom_tiny_bench.estimator:[IRT] predicted score for 0_th model in gqa: 0.642471\n",
      "INFO:custom_tiny_bench.estimator:[Naive accuracy]: 0.660000\n",
      "INFO:custom_tiny_bench.estimator:[IRT] predicted score for 0_th model in text-vqa: 0.630400\n",
      "INFO:custom_tiny_bench.estimator:[p-IRT] predicted score for 0_th model in gqa: 0.662615\n",
      "INFO:custom_tiny_bench.estimator:[p-IRT] predicted score for 0_th model in text-vqa: 0.621258\n",
      "INFO:custom_tiny_bench.estimator:[gp-IRT] predicted score for 0_th model in gqa: 0.644777\n",
      "INFO:custom_tiny_bench.estimator:[gp-IRT] predicted score for 0_th model in text-vqa: 0.629734\n"
     ]
    }
   ],
   "source": [
    "res = tinybm.estimate_performance(p_irt=p_irt, gp_irt=gp_irt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on gqa\n",
      "Model 0\n",
      "    [Balanced true accruacy] 0.64406\n",
      "    [Random] scenario: gqa, avg. error: 0.03594\n",
      "    [IRT] scenario: gqa, avg. error: 0.00159\n",
      "    [p-IRT] scenario: gqa, avg. error: 0.01855\n",
      "    [gp-IRT] scenario: gqa, avg. error: 0.00072\n",
      "Result on text-vqa\n",
      "Model 0\n",
      "    [Balanced true accruacy] 0.62520\n",
      "    [Random] scenario: text-vqa, avg. error: 0.01480\n",
      "    [IRT] scenario: text-vqa, avg. error: 0.00520\n",
      "    [p-IRT] scenario: text-vqa, avg. error: 0.00394\n",
      "    [gp-IRT] scenario: text-vqa, avg. error: 0.00453\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Random sampling \n",
    "qids = np.array(range(5000))\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "for scenario in tinybm.scenarios_position.keys():\n",
    "    random_points = rng.choice(qids, size=number_item, replace=False)\n",
    "    equal_weights = np.array([1/number_item for _ in range(number_item)])\n",
    "\n",
    "    Y_random = tinybm.test_data[:,tinybm.scenarios_position[scenario]][:,random_points]\n",
    "    Y_hat = (Y_random*equal_weights).sum(axis=1)\n",
    "    Balanced_true = (tinybm.balance_weights*tinybm.test_data)[:,tinybm.scenarios_position[scenario]].mean(axis=1) \n",
    "\n",
    "    print(f\"Result on {scenario}\")\n",
    "    for i in range(Balanced_true.shape[0]):\n",
    "        print(f\"Model {i}\")\n",
    "        print(f\"    [Balanced true accruacy] {Balanced_true[i]:.5f}\")\n",
    "        print(f\"    [Random] scenario: {scenario}, avg. error: {np.abs(Y_hat[i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [IRT] scenario: {scenario}, avg. error: {np.abs(res[0][scenario][i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [p-IRT] scenario: {scenario}, avg. error: {np.abs(res[1][scenario][i]-Balanced_true[i]):.5f}\")\n",
    "        print(f\"    [gp-IRT] scenario: {scenario}, avg. error: {np.abs(res[2][scenario][i]-Balanced_true[i]):.5f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
