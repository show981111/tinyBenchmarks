{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Training Item Response Theory (IRT) models\n",
    "\n",
    "In this notebook, we show how to train your own Item Response Theory (IRT) models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9b93-5059-416c-8a53-e3b4cc24a904",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from irt import *\n",
    "from utils import *\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb8ce2-1851-4131-8d35-36214be71085",
   "metadata": {},
   "source": [
    "The leaderboard dataset we will use is composed by six scenarios (sub-datasets):\n",
    "1. TruthfulQA\n",
    "1. GSM8K\n",
    "1. Winogrande\n",
    "1. ARC\n",
    "1. HellaSwag\n",
    "1. MMLU\n",
    "\n",
    "MMLU is further divided into sub-scenarios (e.g., abstract algebra, anatomy, etc). Let's check scenarios and sub-scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harness_truthfulqa_mc_0': ['harness_truthfulqa_mc_0'],\n",
       " 'gsm8k': ['harness_gsm8k_5'],\n",
       " 'winogrande': ['harness_winogrande_5'],\n",
       " 'arc': ['harness_arc_challenge_25'],\n",
       " 'hellaswag': ['harness_hellaswag_10'],\n",
       " 'mmlu': ['harness_hendrycksTest_abstract_algebra_5',\n",
       "  'harness_hendrycksTest_anatomy_5',\n",
       "  'harness_hendrycksTest_astronomy_5',\n",
       "  'harness_hendrycksTest_business_ethics_5',\n",
       "  'harness_hendrycksTest_clinical_knowledge_5',\n",
       "  'harness_hendrycksTest_college_biology_5',\n",
       "  'harness_hendrycksTest_college_chemistry_5',\n",
       "  'harness_hendrycksTest_college_computer_science_5',\n",
       "  'harness_hendrycksTest_college_mathematics_5',\n",
       "  'harness_hendrycksTest_college_medicine_5',\n",
       "  'harness_hendrycksTest_college_physics_5',\n",
       "  'harness_hendrycksTest_computer_security_5',\n",
       "  'harness_hendrycksTest_conceptual_physics_5',\n",
       "  'harness_hendrycksTest_econometrics_5',\n",
       "  'harness_hendrycksTest_electrical_engineering_5',\n",
       "  'harness_hendrycksTest_elementary_mathematics_5',\n",
       "  'harness_hendrycksTest_formal_logic_5',\n",
       "  'harness_hendrycksTest_global_facts_5',\n",
       "  'harness_hendrycksTest_high_school_biology_5',\n",
       "  'harness_hendrycksTest_high_school_chemistry_5',\n",
       "  'harness_hendrycksTest_high_school_computer_science_5',\n",
       "  'harness_hendrycksTest_high_school_european_history_5',\n",
       "  'harness_hendrycksTest_high_school_geography_5',\n",
       "  'harness_hendrycksTest_high_school_government_and_politics_5',\n",
       "  'harness_hendrycksTest_high_school_macroeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_mathematics_5',\n",
       "  'harness_hendrycksTest_high_school_microeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_physics_5',\n",
       "  'harness_hendrycksTest_high_school_psychology_5',\n",
       "  'harness_hendrycksTest_high_school_statistics_5',\n",
       "  'harness_hendrycksTest_high_school_us_history_5',\n",
       "  'harness_hendrycksTest_high_school_world_history_5',\n",
       "  'harness_hendrycksTest_human_aging_5',\n",
       "  'harness_hendrycksTest_human_sexuality_5',\n",
       "  'harness_hendrycksTest_international_law_5',\n",
       "  'harness_hendrycksTest_jurisprudence_5',\n",
       "  'harness_hendrycksTest_logical_fallacies_5',\n",
       "  'harness_hendrycksTest_machine_learning_5',\n",
       "  'harness_hendrycksTest_management_5',\n",
       "  'harness_hendrycksTest_marketing_5',\n",
       "  'harness_hendrycksTest_medical_genetics_5',\n",
       "  'harness_hendrycksTest_miscellaneous_5',\n",
       "  'harness_hendrycksTest_moral_disputes_5',\n",
       "  'harness_hendrycksTest_moral_scenarios_5',\n",
       "  'harness_hendrycksTest_nutrition_5',\n",
       "  'harness_hendrycksTest_philosophy_5',\n",
       "  'harness_hendrycksTest_prehistory_5',\n",
       "  'harness_hendrycksTest_professional_accounting_5',\n",
       "  'harness_hendrycksTest_professional_law_5',\n",
       "  'harness_hendrycksTest_professional_medicine_5',\n",
       "  'harness_hendrycksTest_professional_psychology_5',\n",
       "  'harness_hendrycksTest_public_relations_5',\n",
       "  'harness_hendrycksTest_security_studies_5',\n",
       "  'harness_hendrycksTest_sociology_5',\n",
       "  'harness_hendrycksTest_us_foreign_policy_5',\n",
       "  'harness_hendrycksTest_virology_5',\n",
       "  'harness_hendrycksTest_world_religions_5']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading leaderboard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lb.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14f180-d322-4cd5-8d0c-4ae4fef04127",
   "metadata": {},
   "source": [
    "In this dataset, we have data from 395 models. Let's see the names of some of them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6c4201-0675-42e5-8a7a-8cf75592e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395,\n",
       " ['open-llm-leaderboard/details_zhengr__MixTAO-7Bx2-MoE-DPO',\n",
       "  'open-llm-leaderboard/details_alignment-handbook__zephyr-7b-sft-full',\n",
       "  'open-llm-leaderboard/details_rombodawg__Leaderboard-killer-MoE_4x7b',\n",
       "  'open-llm-leaderboard/details_FelixChao__ExtremeDolphin-MoE',\n",
       "  'open-llm-leaderboard/details_LoSboccacc__orthogonal-2x7B-base',\n",
       "  'open-llm-leaderboard/details_moreh__MoMo-70B-lora-1.8.6-DPO',\n",
       "  'open-llm-leaderboard/details_deepseek-ai__deepseek-moe-16b-base',\n",
       "  'open-llm-leaderboard/details_Swisslex__Mixtral-Orca-v0.1',\n",
       "  'open-llm-leaderboard/details_wang7776__Mistral-7B-Instruct-v0.2-sparsity-20',\n",
       "  'open-llm-leaderboard/details_nfaheem__Marcoroni-7b-DPO-Merge'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['models']),data['models'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 28659)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(scenarios, data)\n",
    "Y = create_responses(scenarios, data)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "For example, below you can see the scores for MMLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [1., 0., 1., ..., 1., 1., 0.]]),\n",
       " (395, 14042))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,scenarios_position['mmlu']], Y[:,scenarios_position['mmlu']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d062bc-1efe-4527-b40c-96fc295e05fe",
   "metadata": {},
   "source": [
    "For scenarios that have multiple subscenarios, it is usually the case that we want to give equal importance to individual subscenarios when computing the aggregated performance in that scenario. This is equivalent to using a weighted average when computing the aggregated performance. We will create balance_weights, a vector of weights to help us compute those weighted averages. These weights will be different than one only for MMLU, which is the only scenario with multiple subscenarios.\n",
    "\n",
    "We will use this when choosing the IRT dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c2e717-c575-4b0c-8067-15574c3dde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_weights = np.ones(Y.shape[1])\n",
    "\n",
    "N = len(scenarios_position['mmlu'])\n",
    "n_sub = len(scenarios['mmlu'])\n",
    "for sub in scenarios['mmlu']:\n",
    "    n_i = len(subscenarios_position['mmlu'][sub])\n",
    "    balance_weights[subscenarios_position['mmlu'][sub]] = N/(n_sub*n_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4dd3af-2d50-4ed5-bc36-09acf3f987fc",
   "metadata": {},
   "source": [
    "We can see below that first averaging within subscenarios and then computing a simple average is equivalent to using a weighted average from the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85903718-e30c-433b-b407-74fc9ebb05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.322333605307685e-14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs1 = np.mean([Y[:,subscenarios_position['mmlu'][sub]].mean(axis=1) for sub in scenarios['mmlu']], axis=0)\n",
    "accs2 = (balance_weights*Y)[:,scenarios_position['mmlu']].mean(axis=1)\n",
    "\n",
    "np.abs(accs1 - accs2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Training IRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c4412-ae69-4184-b106-191a1c151736",
   "metadata": {},
   "source": [
    "Let's split the data in train and test (recent models are placed in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9874c5-7cb5-425b-8c41-9a87d7615ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y[:100]\n",
    "Y_train = Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e856d5-3778-417f-b4e9-77cfc9f6e6a1",
   "metadata": {},
   "source": [
    "To train the IRT model, we first need to binarize the values in $Y$ because correctness is not binary for TruthfulQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739556a1-fd5c-4edb-8fd2-2e0914377eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 100/100 [00:00<00:00, 1015.66it/s]\n",
      "100%|████████████████████████████████████████████| 100/100 [00:00<00:00, 789.99it/s]\n",
      "100%|████████████████████████████████████████████| 100/100 [00:00<00:00, 819.04it/s]\n",
      "100%|████████████████████████████████████████████| 100/100 [00:00<00:00, 887.72it/s]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:01<00:00, 53.19it/s]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:04<00:00, 24.05it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_bin_train = np.zeros(Y_train.shape)\n",
    "Y_bin_test = np.zeros(Y_test.shape)\n",
    "\n",
    "cs = np.linspace(0.01,.99,100)  # Threshold values to consider\n",
    "for scenario in scenarios.keys():\n",
    "    ind = scenarios_position[scenario]\n",
    "    # Find the best threshold value that minimizes the difference between averages\n",
    "    c = cs[np.argmin([np.mean((np.abs((Y_train[:,ind]>c).mean(axis=1)-Y_train[:,ind].mean(axis=1)))) for c in tqdm(cs)])]\n",
    "    # Apply the threshold to train and test responses\n",
    "    Y_bin_train[:,ind] = (Y_train[:,ind]>c).astype(int)\n",
    "    Y_bin_test[:,ind] = (Y_test[:,ind]>c).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964dbee2-3607-4f6a-b287-29f12b5e20d5",
   "metadata": {},
   "source": [
    "Choosing the dimension for the IRT model based on a simple validation heuristic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9999beb9-9796-45ea-993b-cd293d343002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                         | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:16] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[20:56:19] amortized: False                                       dataset.py:112\n",
      "[20:56:38] Vocab size: None                                       training.py:90\n",
      "[20:56:40] Training Model...                                          cli.py:116\n",
      "[20:56:40] args: {'device': 'cuda', 'num_items': 28659,          training.py:134\n",
      "           'num_subjects': 240}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           28659, 'num_subjects': 240, 'priors': 'hierarchical',                \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([6878160]) torch.Size([6878160])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss          ┃ Best Loss     ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 15978692.9609 │ 15978692.9609 │ 0.1000 │\n",
      "│ 201   │ 1876229.9616  │ 1876229.9616  │ 0.0980 │\n",
      "│ 401   │ 1845919.6682  │ 1836453.2076  │ 0.0961 │\n",
      "│ 601   │ 1849739.1237  │ 1827769.4012  │ 0.0942 │\n",
      "│ 801   │ 1826675.5730  │ 1823262.3067  │ 0.0923 │\n",
      "│ 1001  │ 1832429.8052  │ 1820409.7659  │ 0.0905 │\n",
      "│ 1201  │ 1822942.9108  │ 1819273.7322  │ 0.0887 │\n",
      "│ 1401  │ 1820789.1871  │ 1818767.9448  │ 0.0869 │\n",
      "│ 1601  │ 1822483.5398  │ 1818198.3984  │ 0.0852 │\n",
      "│ 1801  │ 1821025.9523  │ 1817465.1269  │ 0.0835 │\n",
      "│ 2000  │ 1817001.8121  │ 1816261.4134  │ 0.0819 │\n",
      "└───────┴───────────────┴───────────────┴────────┘[20:59:22] Train time: 185.5980794429779                              cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████                        | 1/2 [03:29<03:29, 209.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:47] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[20:59:49] amortized: False                                       dataset.py:112\n",
      "[21:00:09] Vocab size: None                                       training.py:90\n",
      "[21:00:10] Training Model...                                          cli.py:116\n",
      "[21:00:10] args: {'device': 'cuda', 'num_items': 28659,          training.py:134\n",
      "           'num_subjects': 240}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           28659, 'num_subjects': 240, 'priors': 'hierarchical',                \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([6878160]) torch.Size([6878160])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss          ┃ Best Loss     ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 29489462.9585 │ 29489462.9585 │ 0.1000 │\n",
      "│ 201   │ 1932133.1287  │ 1918973.6307  │ 0.0980 │\n",
      "│ 401   │ 1810691.4688  │ 1805481.9656  │ 0.0961 │\n",
      "│ 601   │ 1805506.2733  │ 1777641.6299  │ 0.0942 │\n",
      "│ 801   │ 1766209.9010  │ 1762468.7469  │ 0.0923 │\n",
      "│ 1001  │ 1766226.4146  │ 1755757.7828  │ 0.0905 │\n",
      "│ 1201  │ 1756347.7137  │ 1750775.2806  │ 0.0887 │\n",
      "│ 1401  │ 1751416.2395  │ 1748871.1929  │ 0.0869 │\n",
      "│ 1601  │ 1753639.6714  │ 1747985.3278  │ 0.0852 │\n",
      "│ 1801  │ 1750219.1412  │ 1747000.7157  │ 0.0835 │\n",
      "│ 2000  │ 1749129.6322  │ 1746099.5237  │ 0.0819 │\n",
      "└───────┴───────────────┴───────────────┴────────┘[21:03:04] Train time: 197.89136505126953                             cli.py:122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 2/2 [07:32<00:00, 226.08s/it]\n"
     ]
    }
   ],
   "source": [
    "Ds = [5,10] # Dimensions to try\n",
    "device = 'cuda' # Either 'cuda' or 'cpu' \n",
    "epochs = 2000  # Number of epochs for IRT model training (py-irt default is 2000)\n",
    "lr = .1  # Learning rate for IRT model training (py-irt default is .1)\n",
    "\n",
    "val_ind = list(range(0,Y_bin_train.shape[0],5)) # Validation indices\n",
    "train_ind = [i for i in range(Y_bin_train.shape[0]) if i not in val_ind]\n",
    "\n",
    "# Saving the training dataset in the needed format\n",
    "create_irt_dataset(Y_bin_train[train_ind], 'data/irt_val_dataset.jsonlines')\n",
    "\n",
    "# Trying different Ds\n",
    "errors = []  \n",
    "errors2 = []\n",
    "\n",
    "for D in tqdm(Ds):\n",
    "    dataset_name = 'data/irt_val_dataset.jsonlines'\n",
    "    model_name = 'data/irt_val_model/'\n",
    "    \n",
    "    # Load trained IRT model parameters\n",
    "    train_irt_model(dataset_name, model_name, D, lr, epochs, device)\n",
    "    A, B, Theta = load_irt_parameters(model_name)\n",
    "    \n",
    "    # Determine seen and unseen items for validation\n",
    "    seen_items = list(range(0, Y_bin_train.shape[1], 2))\n",
    "    unseen_items = list(range(1, Y_bin_train.shape[1], 2))\n",
    "\n",
    "    # Estimate ability parameters for the validation set\n",
    "    thetas = [estimate_ability_parameters(Y_bin_train[val_ind][j][seen_items], A[:, :, seen_items], B[:, :, seen_items]) for j in range(len(val_ind))]\n",
    "\n",
    "    # Compute validation errors for each scenario and update the errors list (in the end, we give the same weight for all scenarios)\n",
    "    errors2.append([])\n",
    "    for scenario in scenarios.keys():\n",
    "        ind = [u for u in unseen_items if u in scenarios_position[scenario]]\n",
    "        errors2[-1].append(np.mean([abs((balance_weights*item_curve(thetas[j], A, B))[0,ind].mean()-Y_train[val_ind][j,ind].mean())for j in range(len(val_ind))]))\n",
    "    errors.append(np.mean(errors2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efbdc2b3-fb4e-4075-b1df-a747ce7d68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_D = np.argmin(np.array(errors))\n",
    "D = Ds[ind_D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680d6e6-1ec2-4a24-a898-f29bd5ec109e",
   "metadata": {},
   "source": [
    "Saving the training dataset in the needed format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a80e3b-8e0c-402f-8263-7e178b976bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_irt_dataset(Y_bin_train, 'data/irt_dataset.jsonlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa8114-a6b3-493c-8220-9f8976131a53",
   "metadata": {},
   "source": [
    "To train the IRT model, we use an adapted version of `py-irt` code (please check README in the tutorials directory for mode details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7dcda49-4f05-4350-9dcf-d09addc8f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:03:56] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=10 lr=0.1                 \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_dataset.jsonlines                      cli.py:111\n",
      "           output directory: data/irt_model                           cli.py:112\n",
      "[21:04:00] amortized: False                                       dataset.py:112\n",
      "[21:04:24] Vocab size: None                                       training.py:90\n",
      "[21:04:25] Training Model...                                          cli.py:116\n",
      "[21:04:25] args: {'device': 'cuda', 'num_items': 28659,          training.py:134\n",
      "           'num_subjects': 300}                                                 \n",
      "           Parsed Model Args: {'device': 'cuda', 'num_items':    training.py:147\n",
      "           28659, 'num_subjects': 300, 'priors': 'hierarchical',                \n",
      "           'dims': 10, 'dropout': 0.5, 'hidden': 100,                           \n",
      "           'vocab_size': None}                                                  \n",
      "torch.Size([8597700]) torch.Size([8597700])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┏━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
      "┃ Epoch ┃ Loss          ┃ Best Loss     ┃ New LR ┃\n",
      "┡━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
      "│ 1     │ 36807947.1609 │ 36807947.1609 │ 0.1000 │\n",
      "│ 201   │ 2345175.5131  │ 2334518.0218  │ 0.0980 │\n",
      "│ 401   │ 2197054.4552  │ 2191547.9268  │ 0.0961 │\n",
      "│ 601   │ 2184493.8269  │ 2156099.2271  │ 0.0942 │\n",
      "│ 801   │ 2140215.2762  │ 2135749.3029  │ 0.0923 │\n",
      "│ 1001  │ 2137761.0233  │ 2125411.9116  │ 0.0905 │\n",
      "│ 1201  │ 2125121.3248  │ 2121550.6036  │ 0.0887 │\n",
      "│ 1401  │ 2120108.9208  │ 2116538.7992  │ 0.0869 │\n",
      "│ 1601  │ 2120196.5529  │ 2116338.9328  │ 0.0852 │\n",
      "│ 1801  │ 2118998.9564  │ 2114128.1703  │ 0.0835 │\n",
      "│ 2000  │ 2117212.1366  │ 2114128.1703  │ 0.0819 │\n",
      "└───────┴───────────────┴───────────────┴────────┘[21:07:51] Train time: 235.29083228111267                             cli.py:122\n"
     ]
    }
   ],
   "source": [
    "train_irt_model(dataset_name='data/irt_dataset.jsonlines', \n",
    "                model_name='data/irt_model', \n",
    "                D=D, lr=lr, epochs=epochs, device=device)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f46f1",
   "metadata": {},
   "source": [
    "## Get the values for $\\lambda$ which will be used to get the gp-IRT estimates (in conjunction with anchor methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e186b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda(b, v):\n",
    "    return (b**2)/(v+(b**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5c76c",
   "metadata": {},
   "source": [
    "The variable `number_item` gives the number of data points we will sample per scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9962b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_item = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2fd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambds = {} \n",
    "\n",
    "for i,scenario in enumerate(scenarios.keys()):\n",
    "    v = np.var(Y_train[:,scenarios_position[scenario]], axis=1).mean()\n",
    "    b = np.mean(errors2[ind_D][i]) \n",
    "    lambds[scenario] = get_lambda(b, v/(4*number_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b270a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lambds.pickle', 'wb') as handle:\n",
    "    pickle.dump(lambds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
